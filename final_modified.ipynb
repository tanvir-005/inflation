{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d93967",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "Import necessary libraries such as pandas, numpy, matplotlib, seaborn, and machine learning libraries like scikit-learn, XGBoost, and CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25819db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62881d",
   "metadata": {},
   "source": [
    "# Load and Inspect Data\n",
    "Load the dataset using pandas, display its shape, columns, and check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e7bf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (196, 47)\n",
      "\n",
      "Data Columns:\n",
      " Index(['country_name', 'indicator_name', '1980', '1981', '1982', '1983',\n",
      "       '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992',\n",
      "       '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001',\n",
      "       '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010',\n",
      "       '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019',\n",
      "       '2020', '2021', '2022', '2023', '2024'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing Values:\n",
      " country_name       0\n",
      "indicator_name     0\n",
      "1980              56\n",
      "1981              52\n",
      "1982              51\n",
      "1983              51\n",
      "1984              51\n",
      "1985              51\n",
      "1986              51\n",
      "1987              49\n",
      "1988              49\n",
      "1989              49\n",
      "1990              46\n",
      "1991              41\n",
      "1992              38\n",
      "1993              27\n",
      "1994              25\n",
      "1995              24\n",
      "1996              20\n",
      "1997              17\n",
      "1998              15\n",
      "1999              14\n",
      "2000              13\n",
      "2001               9\n",
      "2002               7\n",
      "2003               6\n",
      "2004               5\n",
      "2005               3\n",
      "2006               3\n",
      "2007               3\n",
      "2008               3\n",
      "2009               3\n",
      "2010               3\n",
      "2011               4\n",
      "2012               3\n",
      "2013               2\n",
      "2014               2\n",
      "2015               2\n",
      "2016               2\n",
      "2017               1\n",
      "2018               1\n",
      "2019               1\n",
      "2020               2\n",
      "2021               2\n",
      "2022               2\n",
      "2023               4\n",
      "2024               5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load & Inspect Dataset\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"global_inflation_data.csv\") \n",
    "\n",
    "# Display basic information\n",
    "print(\"Data Shape:\", data.shape)\n",
    "print(\"\\nData Columns:\\n\", data.columns)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\\n\", data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f55f4c",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Fill missing values, separate features and target, and perform train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae3eac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape after preprocessing:\n",
      "X: (141, 44)\n",
      "y: (141,)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Preprocessing\n",
    "\n",
    "# Remove rows with missing target (2024)\n",
    "data = data.dropna(subset=['2024'])\n",
    "\n",
    "# Convert year columns to float and drop rows with too many missing values\n",
    "year_cols = [str(year) for year in range(1980, 2024)]\n",
    "data[year_cols] = data[year_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with more than 5 missing feature values\n",
    "data = data[data[year_cols].isnull().sum(axis=1) <= 5]\n",
    "\n",
    "# Fill remaining missing values with column median\n",
    "data[year_cols] = data[year_cols].fillna(data[year_cols].median())\n",
    "\n",
    "# Define features and target\n",
    "X = data[year_cols]\n",
    "y = data['2024']\n",
    "\n",
    "print(\"Final shape after preprocessing:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c388e7",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "Create visualizations including a line plot for a sample country, a correlation heatmap, and a histogram of 2024 inflation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb3575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (112, 44)\n",
      "Test set size: (29, 44)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train/Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42ca13",
   "metadata": {},
   "source": [
    "# Logistic Regression (Classifying High vs Low Inflation)\n",
    "Classify inflation as high or low using logistic regression, scale features, train the model, and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b32c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 36.2398\n",
      "Baseline MAE: 13.0289\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Baseline Model\n",
    "\n",
    "# Predict mean of training target\n",
    "y_pred_baseline = np.full(shape=y_test.shape, fill_value=y_train.mean())\n",
    "\n",
    "# Evaluation metrics\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"Baseline RMSE: {rmse_baseline:.4f}\")\n",
    "print(f\"Baseline MAE: {mae_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5b608",
   "metadata": {},
   "source": [
    "# Ensemble Models: RF, XGBoost, CatBoost\n",
    "Train Random Forest, XGBoost, and CatBoost models, make predictions, and perform ensemble averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca893048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 12.9172\n",
      "Random Forest MAE: 4.2158\n",
      "\n",
      "XGBoost RMSE: 9.5396\n",
      "XGBoost MAE: 3.4549\n",
      "\n",
      "CatBoost RMSE: 23.0374\n",
      "CatBoost MAE: 6.5220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train Individual Models\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# CatBoost\n",
    "cat = CatBoostRegressor(iterations=100, random_state=42, verbose=0)\n",
    "cat.fit(X_train, y_train)\n",
    "y_pred_cat = cat.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"{model_name} RMSE: {rmse:.4f}\")\n",
    "    print(f\"{model_name} MAE: {mae:.4f}\")\n",
    "    print()\n",
    "\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "evaluate_model(y_test, y_pred_cat, \"CatBoost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae381a8",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Evaluate the performance of individual models and the ensemble using RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c78d53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor RMSE: 50.5461\n",
      "Stacking Regressor MAE: 12.8916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Ensemble Model - Stacking\n",
    "\n",
    "# Define base models\n",
    "base_learners = [\n",
    "    ('rf', rf),\n",
    "    ('xgb', xgb),\n",
    "    ('cat', cat)\n",
    "]\n",
    "\n",
    "# Define the stacking regressor with a Linear Regression meta-model\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "evaluate_model(y_test, y_pred_stack, \"Stacking Regressor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d42505",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Summarize findings, discuss the effectiveness of ensemble methods, and suggest future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d637e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Random Forest Score: 18.545188072209495\n",
      "Tuned Random Forest RMSE: 12.2708\n",
      "Tuned Random Forest MAE: 4.3052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Hyperparameter Tuning - Random Forest\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Random Forest Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best Random Forest Score:\", np.sqrt(-grid_search_rf.best_score_))\n",
    "\n",
    "# Evaluate the best Random Forest model\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_best_rf, \"Tuned Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd41b52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150, 'subsample': 1.0}\n",
      "Best XGBoost Score: 12.342216647767778\n",
      "Tuned XGBoost RMSE: 9.6498\n",
      "Tuned XGBoost MAE: 3.7314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Hyperparameter Tuning - XGBoost\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(XGBRegressor(random_state=42, verbosity=0), param_grid_xgb, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best XGBoost Parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best XGBoost Score:\", np.sqrt(-grid_search_xgb.best_score_))\n",
    "\n",
    "# Evaluate the best XGBoost model\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "y_pred_best_xgb = best_xgb.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_best_xgb, \"Tuned XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc1d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost Parameters: {'depth': 6, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
      "Best CatBoost Score: 22.83101795044936\n",
      "Tuned CatBoost RMSE: 23.3246\n",
      "Tuned CatBoost MAE: 6.1382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Hyperparameter Tuning - CatBoost\n",
    "\n",
    "# Define parameter grid for CatBoost\n",
    "param_grid_cat = {\n",
    "    'iterations': [100, 200],\n",
    "    'depth': [6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_cat = GridSearchCV(CatBoostRegressor(random_state=42, verbose=0), param_grid_cat, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_cat.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best CatBoost Parameters:\", grid_search_cat.best_params_)\n",
    "print(\"Best CatBoost Score:\", np.sqrt(-grid_search_cat.best_score_))\n",
    "\n",
    "# Evaluate the best CatBoost model\n",
    "best_cat = grid_search_cat.best_estimator_\n",
    "y_pred_best_cat = best_cat.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_best_cat, \"Tuned CatBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7191c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Stacking Regressor RMSE: 12.5296\n",
      "Updated Stacking Regressor MAE: 4.8589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Ensemble Model - Updated Stacking with Tuned Models\n",
    "\n",
    "# Define base models (tuned)\n",
    "base_learners_tuned = [\n",
    "    ('rf', best_rf),\n",
    "    ('xgb', best_xgb)\n",
    "]\n",
    "\n",
    "# Define the stacking regressor with a Linear Regression meta-model\n",
    "stacking_model_tuned = StackingRegressor(\n",
    "    estimators=base_learners_tuned,\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stack_tuned = stacking_model_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "evaluate_model(y_test, y_pred_stack_tuned, \"Updated Stacking Regressor\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
